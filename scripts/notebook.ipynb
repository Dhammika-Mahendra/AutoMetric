{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43af3316",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bc5b2",
   "metadata": {},
   "source": [
    "# Car Price Prediction using CatBoost\n",
    "\n",
    "This notebook demonstrates a professional approach to building a CatBoost regression model for predicting car prices in Sri Lanka.\n",
    "\n",
    "## Table of Contents\n",
    "1. Import Libraries\n",
    "2. Load and Explore Data\n",
    "3. Data Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Stratified Data Splitting\n",
    "6. Model Training\n",
    "7. Model Evaluation\n",
    "8. Feature Importance Analysis\n",
    "9. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install catboost\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Model\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da19f4",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/car_price.csv')\n",
    "\n",
    "# Remove the first column (ID column - unnamed index)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "# Display basic information\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“Š Dataset Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"\\nðŸ“‹ Column Names:\\n{list(df.columns)}\")\n",
    "print(f\"\\nðŸ” First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA TYPES AND MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“ Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nâŒ Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nðŸ“ˆ Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20897f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution (Price is in 10000s)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Price distribution\n",
    "axes[0].hist(df['Price'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_xlabel('Price (in 10,000s LKR)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Car Prices')\n",
    "axes[0].axvline(df['Price'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"Price\"].mean():.2f}')\n",
    "axes[0].axvline(df['Price'].median(), color='green', linestyle='--', label=f'Median: {df[\"Price\"].median():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-transformed price distribution\n",
    "axes[1].hist(np.log1p(df['Price']), bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].set_xlabel('Log(Price + 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Log-Transformed Price Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’° Price Statistics (in 10,000s LKR):\")\n",
    "print(f\"   Min: {df['Price'].min():.2f} | Max: {df['Price'].max():.2f}\")\n",
    "print(f\"   Mean: {df['Price'].mean():.2f} | Median: {df['Price'].median():.2f}\")\n",
    "print(f\"   Std: {df['Price'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e979a",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df49d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols.remove('Price')  # Remove target variable\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COLUMN CLASSIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“Š Categorical Columns ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"   â€¢ {col}: {df_processed[col].nunique()} unique values\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Numerical Columns ({len(numerical_cols)}):\")\n",
    "for col in numerical_cols:\n",
    "    print(f\"   â€¢ {col}: Range [{df_processed[col].min():.2f}, {df_processed[col].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18978d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for missing values\n",
    "missing_before = df_processed.isnull().sum().sum()\n",
    "print(f\"\\nâŒ Total missing values before: {missing_before}\")\n",
    "\n",
    "# Fill numerical missing values with median\n",
    "for col in numerical_cols:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        median_val = df_processed[col].median()\n",
    "        df_processed[col].fillna(median_val, inplace=True)\n",
    "        print(f\"   â€¢ {col}: Filled with median = {median_val:.2f}\")\n",
    "\n",
    "# Fill categorical missing values with mode\n",
    "for col in categorical_cols:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        mode_val = df_processed[col].mode()[0]\n",
    "        df_processed[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"   â€¢ {col}: Filled with mode = {mode_val}\")\n",
    "\n",
    "missing_after = df_processed.isnull().sum().sum()\n",
    "print(f\"\\nâœ… Total missing values after: {missing_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fbece",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29025809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert Date to datetime and extract features\n",
    "df_processed['Date'] = pd.to_datetime(df_processed['Date'])\n",
    "df_processed['Listing_Year'] = df_processed['Date'].dt.year\n",
    "df_processed['Listing_Month'] = df_processed['Date'].dt.month\n",
    "df_processed['Listing_Day'] = df_processed['Date'].dt.day\n",
    "\n",
    "# Calculate car age (from Year of Manufacture to listing date)\n",
    "df_processed['Car_Age'] = df_processed['Listing_Year'] - df_processed['YOM']\n",
    "\n",
    "# Calculate average mileage per year\n",
    "df_processed['Mileage_Per_Year'] = df_processed['Millage(KM)'] / (df_processed['Car_Age'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# Drop the original Date column as we've extracted features\n",
    "df_processed = df_processed.drop('Date', axis=1)\n",
    "\n",
    "# Create price bins for stratified splitting (based on price ranges)\n",
    "df_processed['Price_Bin'] = pd.qcut(df_processed['Price'], q=5, labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])\n",
    "\n",
    "print(\"\\nâœ… New Features Created:\")\n",
    "print(\"   â€¢ Listing_Year: Year when the car was listed\")\n",
    "print(\"   â€¢ Listing_Month: Month when the car was listed\")\n",
    "print(\"   â€¢ Listing_Day: Day when the car was listed\")\n",
    "print(\"   â€¢ Car_Age: Age of the car in years\")\n",
    "print(\"   â€¢ Mileage_Per_Year: Average kilometers driven per year\")\n",
    "print(\"   â€¢ Price_Bin: Price category for stratified splitting\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Updated Dataset Shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6732e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Select only numerical columns for correlation\n",
    "num_cols_for_corr = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "correlation_matrix = df_processed[num_cols_for_corr].corr()\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "            fmt='.2f', linewidths=0.5, square=True)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlation with Price\n",
    "print(\"\\nðŸ“Š Correlation with Price:\")\n",
    "price_corr = correlation_matrix['Price'].sort_values(ascending=False)\n",
    "for feature, corr in price_corr.items():\n",
    "    if feature != 'Price':\n",
    "        bar = 'â–ˆ' * int(abs(corr) * 20)\n",
    "        sign = '+' if corr > 0 else '-'\n",
    "        print(f\"   {feature:20s}: {sign}{abs(corr):.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a5d4c",
   "metadata": {},
   "source": [
    "## 5. Stratified Data Splitting\n",
    "\n",
    "Using stratified splitting based on Brand and Price categories to ensure:\n",
    "- Representative distribution of car brands in both train and test sets\n",
    "- Similar price distributions in both sets\n",
    "- Better generalization of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "print(\"=\" * 60)\n",
    "print(\"STRATIFIED DATA SPLITTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create stratification key combining Brand and Price_Bin\n",
    "# This ensures both brand diversity and price range diversity in train/test sets\n",
    "df_processed['Stratify_Key'] = df_processed['Brand'].astype(str) + '_' + df_processed['Price_Bin'].astype(str)\n",
    "\n",
    "# Handle rare combinations by grouping them\n",
    "stratify_counts = df_processed['Stratify_Key'].value_counts()\n",
    "rare_combinations = stratify_counts[stratify_counts < 2].index\n",
    "df_processed.loc[df_processed['Stratify_Key'].isin(rare_combinations), 'Stratify_Key'] = 'Other'\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop(['Price', 'Price_Bin', 'Stratify_Key'], axis=1)\n",
    "y = df_processed['Price']\n",
    "stratify_key = df_processed['Stratify_Key']\n",
    "\n",
    "# Identify categorical features for CatBoost (excluding the Date which is already dropped)\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "print(f\"\\nðŸ“Š Features Shape: {X.shape}\")\n",
    "print(f\"ðŸ“Š Target Shape: {y.shape}\")\n",
    "print(f\"\\nðŸ·ï¸ Categorical Features for CatBoost: {cat_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98335209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=stratify_key\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Stratified Split Completed!\")\n",
    "print(f\"\\nðŸ“Š Training Set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"ðŸ“Š Test Set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification - compare brand distributions\n",
    "print(\"\\nðŸ“ˆ Brand Distribution Comparison:\")\n",
    "train_brand_dist = X_train['Brand'].value_counts(normalize=True).head(5)\n",
    "test_brand_dist = X_test['Brand'].value_counts(normalize=True).head(5)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Train %': train_brand_dist * 100,\n",
    "    'Test %': test_brand_dist * 100\n",
    "}).round(2)\n",
    "print(comparison_df)\n",
    "\n",
    "# Verify price distribution similarity\n",
    "print(\"\\nðŸ“ˆ Price Distribution Comparison:\")\n",
    "print(f\"   Train - Mean: {y_train.mean():.2f}, Median: {y_train.median():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"   Test  - Mean: {y_test.mean():.2f}, Median: {y_test.median():.2f}, Std: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12687480",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Training CatBoost Regressor with optimized hyperparameters. CatBoost handles categorical features natively without encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of categorical features\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in cat_features]\n",
    "\n",
    "# Create CatBoost Pools (optimized data format for CatBoost)\n",
    "train_pool = Pool(\n",
    "    data=X_train, \n",
    "    label=y_train, \n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    data=X_test, \n",
    "    label=y_test, \n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "print(\"âœ… CatBoost Pools created successfully!\")\n",
    "print(f\"\\nðŸ“Š Training Pool: {train_pool.num_row()} samples, {train_pool.num_col()} features\")\n",
    "print(f\"ðŸ“Š Test Pool: {test_pool.num_row()} samples, {test_pool.num_col()} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4504d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train CatBoost model\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CATBOOST MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define the model with optimized hyperparameters\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3,\n",
    "    min_data_in_leaf=5,\n",
    "    random_strength=1,\n",
    "    bagging_temperature=0.5,\n",
    "    border_count=128,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nðŸš€ Starting model training...\\n\")\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=test_pool,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Model training completed!\")\n",
    "print(f\"ðŸ“Š Best iteration: {model.get_best_iteration()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b50187",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred, set_name):\n",
    "    \"\"\"Calculate and return regression metrics\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Set': set_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ² Score': r2,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "\n",
    "# Calculate metrics for both sets\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, 'Training')\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, 'Test')\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ“Š Performance Metrics (Price in 10,000s LKR):\\n\")\n",
    "\n",
    "metrics_df = pd.DataFrame([train_metrics, test_metrics])\n",
    "metrics_df = metrics_df.set_index('Set')\n",
    "print(metrics_df.round(4).to_string())\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "âœ… RÂ² Score: {test_metrics['RÂ² Score']:.4f}\n",
    "   â†’ Model explains {test_metrics['RÂ² Score']*100:.2f}% of the variance in car prices\n",
    "\n",
    "âœ… RMSE: {test_metrics['RMSE']:.4f} (in 10,000s LKR)\n",
    "   â†’ Average prediction error: ~{test_metrics['RMSE']*10000:.0f} LKR\n",
    "\n",
    "âœ… MAE: {test_metrics['MAE']:.4f} (in 10,000s LKR)\n",
    "   â†’ Average absolute error: ~{test_metrics['MAE']*10000:.0f} LKR\n",
    "\n",
    "âœ… MAPE: {test_metrics['MAPE (%)']:.2f}%\n",
    "   â†’ Average percentage error in predictions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Actual vs Predicted (Training)\n",
    "axes[0, 0].scatter(y_train, y_train_pred, alpha=0.5, color='steelblue', edgecolors='white', linewidth=0.5)\n",
    "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Price (10,000s LKR)')\n",
    "axes[0, 0].set_ylabel('Predicted Price (10,000s LKR)')\n",
    "axes[0, 0].set_title(f'Training Set: Actual vs Predicted\\nRÂ² = {train_metrics[\"RÂ² Score\"]:.4f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Actual vs Predicted (Test)\n",
    "axes[0, 1].scatter(y_test, y_test_pred, alpha=0.5, color='coral', edgecolors='white', linewidth=0.5)\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 1].set_xlabel('Actual Price (10,000s LKR)')\n",
    "axes[0, 1].set_ylabel('Predicted Price (10,000s LKR)')\n",
    "axes[0, 1].set_title(f'Test Set: Actual vs Predicted\\nRÂ² = {test_metrics[\"RÂ² Score\"]:.4f}')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residual Distribution (Test)\n",
    "residuals = y_test - y_test_pred\n",
    "axes[1, 0].hist(residuals, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Residuals (Actual - Predicted)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Residual Distribution (Test Set)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals vs Predicted\n",
    "axes[1, 1].scatter(y_test_pred, residuals, alpha=0.5, color='purple', edgecolors='white', linewidth=0.5)\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Predicted Price (10,000s LKR)')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].set_title('Residuals vs Predicted Values (Test Set)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b14771",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importance = model.get_feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "# Plot feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Horizontal bar chart\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(importance_df)))\n",
    "axes[0].barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "axes[0].set_xlabel('Importance Score')\n",
    "axes[0].set_ylabel('Feature')\n",
    "axes[0].set_title('CatBoost Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Top 10 features pie chart\n",
    "top_10 = importance_df.tail(10)\n",
    "axes[1].pie(top_10['Importance'], labels=top_10['Feature'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=plt.cm.tab10.colors)\n",
    "axes[1].set_title('Top 10 Features by Importance', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE RANKING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ“Š All Features (sorted by importance):\\n\")\n",
    "importance_df_sorted = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "importance_df_sorted.index += 1\n",
    "importance_df_sorted['Importance'] = importance_df_sorted['Importance'].round(2)\n",
    "print(importance_df_sorted.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2d1cf",
   "metadata": {},
   "source": [
    "## 9. Model Persistence\n",
    "\n",
    "Save the trained model for future use in the API or other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218bcb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import os\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "model_dir = '../model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the CatBoost model\n",
    "model_path = os.path.join(model_dir, 'car_price_catboost_model.cbm')\n",
    "model.save_model(model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nâœ… Model saved to: {model_path}\")\n",
    "print(f\"ðŸ“Š Model file size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "\n",
    "# Save feature names and categorical feature indices for inference\n",
    "import json\n",
    "\n",
    "model_metadata = {\n",
    "    'feature_names': feature_names,\n",
    "    'categorical_features': cat_features,\n",
    "    'categorical_feature_indices': cat_feature_indices,\n",
    "    'best_iteration': model.get_best_iteration(),\n",
    "    'metrics': {\n",
    "        'train_r2': train_metrics['RÂ² Score'],\n",
    "        'test_r2': test_metrics['RÂ² Score'],\n",
    "        'train_rmse': train_metrics['RMSE'],\n",
    "        'test_rmse': test_metrics['RMSE']\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(model_dir, 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "print(f\"âœ… Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f91cd1",
   "metadata": {},
   "source": [
    "## 10. Example Prediction\n",
    "\n",
    "Demonstrating how to use the saved model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc58a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and make a sample prediction\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Load model\n",
    "loaded_model = CatBoostRegressor()\n",
    "loaded_model.load_model(model_path)\n",
    "\n",
    "# Sample prediction using a car from the test set\n",
    "sample_idx = 0\n",
    "sample_car = X_test.iloc[[sample_idx]]\n",
    "actual_price = y_test.iloc[sample_idx]\n",
    "predicted_price = loaded_model.predict(sample_car)[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAMPLE PREDICTION DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ“‹ Sample Car Features:\")\n",
    "for col, value in sample_car.iloc[0].items():\n",
    "    print(f\"   â€¢ {col}: {value}\")\n",
    "\n",
    "print(f\"\\nðŸ’° Actual Price: {actual_price:.2f} (Ã— 10,000 LKR) = {actual_price * 10000:,.0f} LKR\")\n",
    "print(f\"ðŸŽ¯ Predicted Price: {predicted_price:.2f} (Ã— 10,000 LKR) = {predicted_price * 10000:,.0f} LKR\")\n",
    "print(f\"ðŸ“Š Difference: {abs(actual_price - predicted_price):.2f} (Ã— 10,000 LKR) = {abs(actual_price - predicted_price) * 10000:,.0f} LKR\")\n",
    "print(f\"ðŸ“ˆ Percentage Error: {abs(actual_price - predicted_price) / actual_price * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4902f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete machine learning pipeline for car price prediction using CatBoost:\n",
    "\n",
    "1. **Data Loading**: Loaded CSV data and removed the ID column\n",
    "2. **Exploratory Data Analysis**: Analyzed distributions and correlations\n",
    "3. **Data Preprocessing**: Handled missing values appropriately\n",
    "4. **Feature Engineering**: Created new features like Car_Age and Mileage_Per_Year\n",
    "5. **Stratified Splitting**: Used stratified sampling based on Brand and Price categories for representative train/test sets\n",
    "6. **Model Training**: Trained CatBoost with optimized hyperparameters and early stopping\n",
    "7. **Evaluation**: Comprehensive metrics including RÂ², RMSE, MAE, and MAPE\n",
    "8. **Feature Importance**: Analyzed which features most influence price predictions\n",
    "9. **Model Persistence**: Saved the model for deployment\n",
    "\n",
    "**Key Advantages of CatBoost:**\n",
    "- Native handling of categorical features (no encoding needed)\n",
    "- Robust to overfitting with ordered boosting\n",
    "- Fast training and prediction\n",
    "- Built-in cross-validation and early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
